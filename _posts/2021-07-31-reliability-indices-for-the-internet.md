---
layout: post
title: Why the internet is broken and how to fix it
thumbnail-img: /assets/img/reliable.jpeg
share-img: /assets/img/reliable.jpeg
cover-img: /assets/img/trust-puzzle.jpeg
gh-repo: coopersmout/coopersmout.github.io
gh-badge: [star, fork, follow]
tags: [open science, internet, algorithm, information, Google, collective action, academia, research, replication crisis, reliability]
comments: true
---

If you were to ask me what is the single biggest problem in the world today, I would say: misinformation. This is not because I think misinformation itself is a problem -- everyone has a right to believe whatever they like, after all -- but because misinformation is the principle cause for inaction on the world’s biggest problems today. Personally, I’m deeply concerned about the immense suffering that runaway climate change will create if we don’t come together very quickly as a global society to address it. This is not news. In fact, we’ve had overwhelming consensus in the scientific community on the understanding that humans are causing climate change for decades now. So why then, is the general population in countries like America and Australia so lukewarm on the topic? And how can we expect politicians to give this matter the attention it deserves, when their constituents don’t care enough to pressure them to act? 

To me, the principle problem here is misinformation, fueled by the inadequacy of the internet as an information-delivery system. Google is the primary method by which people access information on the internet, but Google’s algorithms are designed to maximise advertising revenue, not deliver reliable information. Given this, a lay person might search the internet and discover two media articles about climate change with diametrically opposed views: one article argues that humans are to blame, the other argues that we are not. Each article might reference a peer-reviewed scientific study that was published in a (seemingly) reputable journal and makes a (seemingly) coherent set of arguments to support their conclusion. Without any further information, what is the lay reader expected to conclude? Can we blame them for thinking that the issue is still up for debate and sticking to their preconceived notions? This is how [confirmation bias](https://en.wikipedia.org/wiki/Confirmation_bias) works, after all.

Now imagine a different world, in which that person has access to metrics showing just how reliable/trustworthy each of those two media articles are. Imagine, for example, that their web browser turns to a dark shade of red when viewing an unreliable media source. Now, the person has easy access to an additional signal that might help them overcome their preconceived notions and develop a more informed opinion. Of course, this person would need to trust that the trustworthy ratings were, themselves, trustworthy. But I believe that this trust could be built up over time, particularly if the public have ways to meaningfully interact with and participate in any such system. I also believe such a system is perfectly within our grasp to create, and could be spearheaded by the academic community if we pool our efforts toward this aim. To achieve this future vision, I think we would need four key, interacting components in any new system we might build:

1. Open access. We can’t expect the general public to trust, or come to grips with, research that they don't have access to. At present, the vast majority of research remains locked behind prohibitively expensive paywalls. Is it any wonder that public distrust of science has skyrocketted in recent years, when they can't even see the science itself?
2. Reliability indices for research articles. We also need to develop metrics for whether the science itself can be trusted. The '[replication crisis](https://en.wikipedia.org/wiki/Replication_crisis)' has shocked both the research community and the general public, and is likely a contributing factor to public distrust in science. Our dominant heuristic for 'quality' -- the journal impact factor -- has been shown to be [non-correlated (or, worse yet, inversely correlated) with reliability](https://doi.org/10.1371/journal.pbio.3000117). Meanwhile, recent studies have shown that experts can predict whether certain findings will replicate, suggesting that expert ratings of research reliability could be a useful metric to researchers and the broader public. 
3. Reputation scores for researchers. We also need to know who are the reliable raters and reviewers. If someone provides a 'reliability score' for a newly published study, should we trust it because they themselves have a proven track record of accurately predicting such things? Or should we discard it because they are just guessing at chance? At present, the presiding ‘status symbol’ in academia -- a university position/affiliation -- is achieved through a roundabout process of publishing in ‘prestigious’ journals, rather than an evaluation of their quality as a reviewer. In fact, most peer review occurs behind closed doors, preventing objective scrutiny of the process and actors within it. Meanwhile, platforms like [Stackexchange](https://stackoverflow.com/help/whats-reputation) have demonstrated that ‘reputation scores’ are an effective way to represent the relative value that different users in a community contribute, using very simple feedback mechanisms (e.g., upvotes/downvotes).
4. Translational indices for media articles. Finally, we need to know whether media articles are faithful representations of the underlying research. All too often, journalists are prone to 'sensationalising' new findings, which further decreases the public trust in science. As an extension of the ideas above, it should be possible to develop metrics that indicate which media articles are to be trusted. A new initiative, called Climate Feedback, does just this by getting experts to evaluate media articles have faithfully reported the underlying science or not. Coupled with the above elements, this type of feedback system could radically alter the way the public interacts with media articles and begin to provide a more nuanced view of the scientific consensus.

With these four elements in place, the person in the above example could see that a media article has a low 'reliability score' and then go ‘hunting’ through all the information that lead to that score, so that they can verify for themselves if they agree with the process. In doing so, they might decide that the underlying science is deeply flawed (as per 1), that people more knowledgeable than themselves think that the underlying science is flawed (as per 2), that those researchers who recommend the article are themselves of poor reputation (as per 3), or that the media article has taken liberties in interpreting the underlying science (as per 4). Each of these information sources could be a powerful signal to help that reader make up their mind. In essence, such a system would amount to placing the collective wisdom of the research community at every person's fingertips, thereby allowing them to make more informed decisions than ever before. 

Clearly, the picture I paint here is an idealistic vision, but I also believe it's perfectly within our grasp as a scientific community to create. By embedding a hierarchy of information-reliability into the internet, across multiple layers, I believe we could create a highly efficient and responsive knowledge delivery system. In turn, this system could allow interested citizens around the world to become personally involved in producing and sharing knowledge (‘citizen science’), further enhancing ownership of and, therefore, comfort with, the global knowledge commons. We could conduct research on the system itself ('meta-research'), allowing us to identify and correct bias, while producing optimal research outcomes. Both the system and the knowledge it conveys could evolve dynamically over time, akin to the open source movement, with revised contributions (software, research, reviews, etc.) attracting revised reviews. We could even develop the system to financially reward all those who participate, commensurate with the value they provide, thus offering researchers an alternative path to generate income and specialise according to their unique strengths and circumstances (more on all of these ideas later).

To me, if we are to create such a future, I believe we need to start from the core of the issue: the scholarly publishing system. It's been decades since the internet was developed and yet we, the global research community, are still publishing 'papers' in 'journals' designed for the 18th century printing press (even if those papers are now 'pdfs' and those journals have subsequently moved online). It's about time that academia had a _real_ 'digital revolution', akin to... well, _practically every other industry on earth_, and embraced a highly efficient knowledge communication system fit for the 21st century. Clearly, achieving this goal will require overcoming powerful network effects that keep us locked into the status quo (primarily, the legacy journal system). But I also believe that the global research community has all of the power we need to realise this future -- we just need to start organising effectively (much more effectively than we have been!). It will not be easy, of course, and may take many years to achieve, but hard as it may be, I personally believe that there's too much at stake here not to try. 

*Note: this post is the first in a series of posts in which I'll outline my 'grand vision' for improving academia, with a focus on the practical steps the research community could take to achieve this vision. I'm using this blog largely to help organise my thoughts and get them out there, because I've been thinking about these ideas too long and not writing enough! But of course, I would love to hear any feedback or comments you might have :)*


