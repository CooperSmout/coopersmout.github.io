---
layout: post
title: Investigating Ivermectin
thumbnail-img: /assets/img/magnifying-glass.png.jpeg
share-img: /assets/img/magnifying-glass.png.jpeg
cover-img: /assets/img/magnifying-glass.png.jpeg
gh-repo: coopersmout/homepage
gh-badge: [star, fork, follow]
tags: [covid, science, internet, information, Google, reliability, academia]
comments: true
---

I recently had a conversation with a friend about COVID-19, in which he expressed his belief that the vaccine was not the most effective way to deal with COVID and that we should be using Ivermectin instead, which had been proven as an effective treatment. My first instinct was to think that I would probably have heard more about this drug via my research networks if it had been shown to be effective, but since I didn't know any specifics on the matter I decided to just take the information on board and look it up later. Just a few minutes ago I started that search, but stopped when it struck me that processes I use to search the internet for information are probably very different to those that my friend would use. This comes from a place of privilige -- the privilige to have been born in a country and circumstances where I could study science at university and then spend many years completing a research PhD, all funded by the Australian tax payer. As researchers, I feel we have a duty of care to share what knowledge we acquire with the general public, hence why I am a staunch advocate for [open science practices](https://coopersmout.com/openscience/). But as much as I hope my work will help in the fight against [misinformation on a global scale](https://coopersmout.com/2021-07-31-reliability-indices-for-the-internet/), I feel I could still be doing more on a local scale to help friends and family navigate the tide of misinformation that is all too readily available these days. As such, I felt that there might be some small value in paying close attention to the steps and reasoning that I take when hunting for reliable information on the internet, so that I can relay those steps to other people. And since I was at my computer anyway, I figured I may as well record those steps here, for anyone who may be interested. This blog post represents the steps that I took to investigate Ivermectin, written in real-time as I undertake each step. 

1. Go to [Google Scholar](https://scholar.google.com/). First and foremost, regular old public-facing [Google](https://www.google.com/) is an advertising algorithm designed to maximise Google's profits, rather than delivering reliable information. So going to Google for reliable information is like going to a used car salesman to diagnose that small spot on my back. In contrast, Google Scholar only indexes scholarly articles -- actual research conducted by researchers. The algorithm is still controlled by Google and I'd much prefer that it were open and researcher-controlled, but that's a fight for another day. For now, we know that Google Scholar returns a more complete set of results than the alternatives (Scopus, Web of Science) and so is, as far as I know, the best available option for finding reliable information.
2. Enter "ivermectin covid" into the search bar. This brings up a number of results. Ordinarily, I would just start from the top here and work my way down, looking at the title and date of each article, but given how rapidly COVID research is evolving, I wanted to make sure I had the latest information, hence...
3. Click 'Since 2021' (left hand of window). This now brings up a list of more recent articles, like so:

![Screenshot of my Ivermectin search](/assets/img/ivermectin-covid.png){: .mx-auto.d-block :}

4. Work down the list. What am I looking at? Well, this isn't my field of expertise, so I'm not expecting to recognise any names. Instead, I'm looking at the article title and the source, i.e. the journal and/or publisher. The first article sounds like a report on a single study. After doing many years of science, I no longer trust single studies to tell me anything reliable -- it's all too easy to find a significant result and get it published, even when there's no real effect to be found. This is because the statistical tests we apply use arbitrary cut-offs to determine the 'significance' of the result. In a study that uses a 5% cutoff (_p_ < 0.05), 1 in 20 studies will find a significant result _just by chance alone_. On top of this, journals are much more interested in publishing significant results than they are null results, which mean that single studies should be trusted even less. So, rather than trusting the findings of single studies, I now only really start to trust findings once at least a few studies have shown the same effect (I learned this the hard way, spending months trying to replicate findings from a single study during my PhD!) -- and even then, I remain skeptical. What I'm really looking for is a _meta-analysis_ or a _systematic review_. These are both special types of articles that don't actually conduct original research themself, but rather condense all of the known information on a topic into a single paper. Because they draw on information from multiple sources at once, they are much less prone to chance effects found in single studies, and many will also attempt to account for publication bias introduced by journals' love for novelty. We learned about this slide 

![The hierarchy of scientific evidence](/assets/img/hierarchy-of-evidence.png){: .mx-auto.d-block :}

5. Almost click on the second article. This one seemed promising, since the title indicated it was a review (rather than a single study) and was directly related to my search. But I didn't recognise the journal name and was also was thrown off by the word 'in-sync', so I took a mental note to look at this study if there wasn't anything more reliable to look into.

6. Click on the third article. Bingo. The title is clear and simple, indicating it's about what I'm interested in and nothing else. But above all, I recognised the word Cochrane, which I know to be associated with the reliability movement in Medicine. As far as I know, Cochrane reviews are the highest-quality reviews of medical literature, using rigorous and systematic approaches to select the highest-quality evidence (e.g., randomised controlled trials) and analysing it in ways that control for bias as much as possible. As far as medical evidence goes, Cochrane reviews are the cream of the crop.
7. Read the [abstract](https://doi.org/10.1002/14651858.CD015017.pub2). Background, objectives, methods, selection criteria, data analysis/collection -- so far so good as everything seems to make sense (given my lack of expertise in this field). First red flag is under main results -- "No study compared ivermectin to an intervention with proven efficacy". Well that's not looking good for Ivermectin. Moving on, "14 studies" -- not very many at all, in the grand scheme of things. And finally, a string of results beginning with "We are uncertain whether..." and including the words "very low-certainty evidence" after the statistical results.
8. Read the conclusion. I think this part is pretty self-explanatory:
"Based on the current very low‐ to low‐certainty evidence, we are uncertain about the efficacy and safety of ivermectin used to treat or prevent COVID‐19. The completed studies are small and few are considered high quality. Several studies are underway that may produce clearer answers in review updates. Overall, the reliable evidence available does not support the use of ivermectin for treatment or prevention of COVID‐19 outside of well‐designed randomized trials."
9. Consider whether I should read the article. Normally I would suggest this is best practice, but given the reputaiton of Cochrane reviews and the state of my rumbling tummy, I decide I should probably go review some breakfast instead.
10. 

_Did you find this post helpful? Let me know below, as it would encourage me to write more posts like this as I look into questions and uncertainty around COVID and other pressing global issues._
