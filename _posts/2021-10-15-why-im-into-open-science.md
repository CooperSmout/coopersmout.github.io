---
layout: post
title: Why I'm into open science
thumbnail-img: /assets/img/tenets-of-open-science.png
share-img: /assets/img/tenets-of-open-science.png
cover-img: /assets/img/burnout.jpeg
gh-repo: coopersmout/homepage
gh-badge: [star, fork, follow]
tags: [publishing, academia, burnout, science, internet, information, Google, reliability]
comments: true
---

*This blog is the prelude to a series of posts in which I outline my vision for an information revolution within academia and beyond. In my [first post](https://coopersmout.com/2021-07-31-reliability-indices-for-the-internet/), I described the end-goal: tackling misinformation by developing a new knowledge system based on the reliability of information. In this next post, I jump back in time to share the experiences that started me thinking about these ideas in the first place.*


## Prelude
### A waste of time
About 5 years ago I tried to get my first paper published. I say 'tried', because the paper was desk-rejected on the grounds that it wasn't novel enough. We had adapted a new technique to find neural representations of subjectively invisible stimuli and then shown that these representations were modulated by attention. The first finding was completely novel, whereas the second provided strong support for a theory that had been debated extensively in the literature, but IMHO not yet reached a concrete resolution. And yet, after what was likely a cursory glance, a single academic editor had struck down any chance of publication on the grounds that it wasn't 'sexy' enough for their particular journal.

Well, not to worry -- I was told -- this happens all the time. So I picked myself up, rewrote parts of the paper, reformatted the article, and submitted to another journal with a lower impact factor (which I had recently discovered was important to an academic career)... only to be desk-rejected again. The third journal sent the article out for peer review, at least, but then subsequently rejected it on the grounds of insufficient novelty and a critique of our interpretation. On our fourth attempt, the paper was finally [published in the Journal of Cognitive Neuroscience](https://doi.org/10.1162/jocn_a_01283) after multiple rounds of peer review. All up, the process took 2 years, 4 journals, 4 editors, 7 peer reviewers, 4 rounds of peer review, and countless hours on the part of my supervisor and me. All of this to publish what was essentially the same information at the beginning of the process. Sure, the paper had changed, but only in superficial ways relating to the 'story' we told (e.g., why our findings were indeed 'novel enough') -- the hypotheses, method, data, results, and conclusions didn't change one bit. None of the reviews were made public, preventing insights into our work that other researchers might have appreciated, and our original drafts were buried, obscuring the journey that our paper had gone through. All in all, I found myself marvelling at the complete waste of time and effort this process had taken.

### Misaligned incentives
Even worse than the wasted effort was the nagging feeling that my work would somehow be more 'publishable' if only I tweaked the story here, or omitted a particular detail there. I had discovered that *being a successful academic is not the same thing as being a good scientist*! I was heartbroken -- fresh out of an undergraduate degree in psychology, where I had learned about cognitive bias and how to overcome it by adhering to scientific principles, I now discovered that the academic reward system was largely oblivious to these ideals and, in some ways, directly antagonistic to them. As a former architect, I began to wonder who had designed such a broken system, or at least who had let it evolve into the mess it is today. And so began a deep dive into the publishing industry, which revealed a [history of manipulation](https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science) by a [handful of monopolistic publishing corporations](https://doi.org/10.1371/journal.pone.0127502), with generations of researchers complicit in their creation of powerful journal 'brands' that still dominate the publishing landscape today.

### A new hope
I began to think about how I might design the system, if we were to start from scratch today. Shortly after, I realised that many of my ideas had already been proposed (e.g., **open evaluation** on multiple dimensions of interest, e.g., novelity, reliability, etc.; [Kriegeskorte](https://doi.org/10.3389/fncom.2012.00079)) or developed into fully fledged journals (e.g., community-owned **open access** journals that make all articles freely available via the internet). And so began the second big question: if we already know what the solutions are, why aren't we doing them already? I realised that everyone is trapped in a giant [collective action problem](https://en.wikipedia.org/wiki/Collective_action_problem), whereby the collective community could benefit greatly through the adoption of open science principles and practices, but individuals have strong incentives to continue acting in ways that ultimately hurt their community (e.g., publishing in slow, expensive, privately-owned journals). I felt that some part of the solution must be to cooperate more effectively, and subsequently began to develop [Project Free Our Knowledge](https://freeourknowledge.org/) to motivate collective action between researchers. But all along, I kept thinking about alternative publishing models that might help free researchers from the clutches of 'prestige', such that we can get on with developing a scholarly communication and evaluation system fit for the 21st century.

### A new beginning
After years of thinking about these ideas and discussing them with practically every scientist I could get my hands on, I'm now in the fortunate position where I can devote all of my energy to making them a reality. As a first step, I'll be releasing my full set of ideas -- in their rough and unpolished form -- via this blog over the coming months. Most of these ideas centre on a novel scholarly publishing model that I believe could create the necessary 'seed conditions' to disrupt the scholarly publishing system and eventually foster a [global information revolution](https://coopersmout.com/2021-07-31-reliability-indices-for-the-internet/). My next post will serve as an overview of that model. Future posts will go through the relevant background information, various parts of the model, and suggest practical steps for bringing it into fruition. I hope that by sharing these ideas openly, we might stimulate discussion and begin to coalesce around a common vision for the future of academia. I'm particularly keen for feedback, critique, and ideas to take this proposal forward. So if any of these ideas strike a chord with you, please reach out and let's work together to make them a reality. I believe the collective research community is incredibly intelligent, highly motivated, and possesses all of the power we need to create whatever future we want to see -- we just need to work together to make it happen.


*Do you have any feedback on any of this? Let me know in the comments below! Stay tuned for the next blog post, where I'll introduce my proposed model for tackling the 'prestige problem' in academia.*

Thumbnail image: Abbeyelder, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0), via Wikimedia Commons
Cover photo: Microbiz Mag, [CC BY 2.0](https://creativecommons.org/licenses/by/2.0), via Wikimedia Commons
