-
layout: post
title: Reliability indices for the internet
share-img: "/assets/img/thumb.jpg"
cover-img: /assets/img/path.jpg
gh-repo: coopersmout/coopersmout.github.io
gh-badge: [star, fork, follow]
tags: [open science, internet, algorithm, information, Google, collective action, academia, research]
comments: true
---

*Note: this post is the first in a series of posts in which I'll outline my 'grand vision' for improving the state of academia, with a focus on the practical steps the research community could take to achieve this vision. I'm using this blog largely to help organise my thoughts and get them out there, since I've been thinking about these ideas too long and not writing enough!*

If you were to ask me what is the single biggest problem in the world today, I would say: misinformation. This is not because I think misinformation itself is a problem -- everyone has a right to believe whatever they like, after all -- but because misinformation is the principle cause for inaction on the world’s biggest problems today. Personally, I’m deeply concerned about the potential for runaway global warming to cause immense suffering in the world, if we don’t come together very quickly as a global society to address it. This is not news -- in fact, we’ve known about this problem and had overwhelming consensus in the scientific community for decades now. So why then, is the general population in highly influential countries like America and Australia so lukewarm on the topic? And how can we expect politicians to give this matter the attention it deserves, when their constituents don’t care enough to pressure them to act? 

To me, the principle problem here is misinformation, fueled by the (lack of) structure to the internet. At present, the typical method for searching the internet is Google, but Google’s algorithms are designed to maximise advertising revenue, not deliver reliable information. Given this, a lay person might search the internet and discover two news articles that present directly opposed views on human-caused climate change: one article argues that humans are to blame, the other argues that we are not. Each article might even reference a peer-reviewed scientific study that was published in a (seemingly reputable) journal and makes a (seemingly) coherent set of arguments to support their conclusion. Without any further information about the reliability of those articles, what is the reader expected to conclude? Can we blame them for concluding that the issue is still up for debate, and sticking to their preconceived notions (this is how [confirmation bias](https://en.wikipedia.org/wiki/Confirmation_bias) works, after all)? 

Now imagine a different world, in which that person has access to metrics showing which of the two media articles should be trusted. Now, the person has an additional signal that might help them overcome their preconceived notions and update their beliefs in line with the latest evidence. Of course, that person would need to trust that the trustworthy ratings were, themselves, trustworthy. But I believe that trust could be built up over time, particularly if the public have ways to meaningfully interact and participate in such a system. Personally, I believe such a system is perfectly within our grasp to create, and could be spearheaded by the academic community. To achieve this future vision, I think we would need four key, interacting components in any new system we might build:

1. Open access. We can’t expect the general public to trust, or come to grips with, research that they don't have access to. At present, the vast majority of research remains locked behind prohibitively expensive paywalls. Is it any wonder that public distrust of science has skyrocketted in recent years?
2. Reliability indices for published research. We also need to have better metrics for whether the underlying research can be trusted. The 'replication crisis' has shocked both the research community and the general public, and is likely a contributing factor to public distrust in science. Our current dominant heuristic for 'quality' -- the journal impact factor -- has been shown to be non-correlated (or, worse yet, inversely correlated) with reliability (BREMBS). Meanwhile, recent studies have shown that experts can predict whether certain findings will replicate, suggesting that expert ratings of research reliability could be a useful metric to the broader public. 
3. Reputation scores for researchers. We also need to know who are the reliable raters and reviewers. If someone provides a replicability estimate of a newly published study, should we trust it because they themselves have a proven track record of accurately predicting such things? Or should we discard it because they are jsut guessing at chance? At present, the presiding ‘status symbol’ in academia -- a university position/affiliation -- is achieved through a roundabout process of publishing in ‘prestigious’ journals, rather than an evaluation of their quality as a reviewer. In fact, most peer review occurs behind closed doors, preventing objective scrutiny of the process and actors within it. Meanwhile, platforms like Stackexchange have demonstrated that ‘reputation scores’ can evolve to reflect the value that users add to the community, using simple feedback mechanisms (e.g., upvotes/downvotes).
4. Translational indices for media articles. Finally, we need to know whether media articles are faithful representations of the underlying research. All too often, journalists are prone to 'sensationalising' new findings, which further decreases the public trust in science. As an extension of the ideas above, it should be possible to develop metrics that indicate which news articles are to be trusted. A new initiative, called Climate Feedback, does just this by getting experts to evaluate media articles have faithfully reported the underlying science or not. Coupled with the above elements, this type of feedback system could radically alter the way the public interacts with media articles and begin to provide a more nuanced view of the scientific consensus.

With these four elements in place, the person in the above example could see that a particular news article has a low trust score and then go ‘hunting’ through all the information that lead to that score, so that they can verify for themselves if they agree with the process. In doing so, they might decide that the underlying science is deeply flawed (as per 1), that people more knowledgeable than themselves think that the underlying science is flawed (as per 2), that those researchers who recommend the article are themselves of questionable reputation (as per 3), or that the media article has taken liberties in interpreting the underlying science (as per 4). Each of these information sources could be a powerful signal to help that reader make up their mind. In essence, such a system would amount to placing the collective wisdom of the research community (and citizen scientists) at every person's fingertips, and allowing them to make more informed decisions than ever before. 

Clearly, the picture I paint here is an idealistic vision, but I also believe it is perfectly within our grasp as a scientific community to create. By embedding a hierarchy of information-reliability into the internet, across multiple layers, I believe we could create a highly efficient and responsive knowledge delivery system. In turn, such a system could allow interested citizens around the world to become personally involved in producing and sharing knowledge (‘citizen science’), further enhancing ownership of and, therefore, comfort with, the global knowledge commons. We could also develop such a system to financially reward all those who participate, commensurate with the value they provide to the global research community (more on this later). To me, if we are to create such a future, I believe we need to start from the core of the issue: the scholarly publishing system. We’ve had decades since the internet was born to develop and adopt progressive scholarly communication systems, but by and large we are still communicating using pre-internet systems (papers, journals). It's time the research community started organising effectively to create *real* change... Because there's too much at stake not to. 
